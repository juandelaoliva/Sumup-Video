{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import cluster\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captura_videos_y_frames(videoName,imagesFolder):\n",
    "    \n",
    "    print ('\\nEn la siguiente ruta se guardarán los frames del video:\\n', imagesFolder,'\\n')\n",
    "    \n",
    "    #capturamos el video\n",
    "    cap = cv2.VideoCapture(videoName)\n",
    "    \n",
    "    #sacamos el frame rate\n",
    "    frameRate = cap.get(5) \n",
    "    \n",
    "    #Array que contendrá los frames del video\n",
    "    frames =[]\n",
    "    \n",
    "    #Array que contendrá los indices del video\n",
    "    nombres=[]\n",
    "    \n",
    "    #sacamos la longitud del video en frames\n",
    "    length = int(cap.get(7))\n",
    "    \n",
    "    \n",
    "    #avisamos si el nombre del video está mal escrito o si el archivo es erróneo\n",
    "    if length==0:\n",
    "        print('\\n\\n\\n¡¡¡¡EL VIDEO NO ES CORRECTO O ESTÁ MAL ESCRITO EL NOMBRE!!!!\\n\\n')\n",
    "        raise ValueError(\"El video '\"+videoName+ \"' es invalido o no existe\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    #Calculamos automáticamente el numero de centros escogiendo 1.25 clusters por minuto y le sumamos 7 más por si es muy corto\n",
    "    numero_centros = int((length//frameRate)/30)+7\n",
    "    \n",
    "    \n",
    "    #sacamos los frames del video original\n",
    "    while(cap.isOpened()):\n",
    "    \n",
    "        frameId = cap.get(1) #numero del frame actual\n",
    "    \n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        \n",
    "        \n",
    "    \n",
    "        #al final solo cojo los frames que son multiplos de 20 para no sobrecargar de información\n",
    "        if (frameId % 20== 0.0):\n",
    "       \n",
    "            #nombre de la imagen\n",
    "            filename = imagesFolder + \"/image_\" +  str(int(frameId)) + \".jpg\"\n",
    "            #escribo la imagen\n",
    "            cv2.imwrite(filename, frame)\n",
    "            frame= cv2.imread(filename)\n",
    "            #meto el frame en la lista frames\n",
    "            frames.append(frame)\n",
    "            #meto el índice en la lista nombres\n",
    "            nombres.append(frameId)\n",
    "            \n",
    "    #cierro la captura del video        \n",
    "    cap.release()\n",
    "    \n",
    "    #avisamos si el nombre del video está mal escrito o si el archivo es erróneo\n",
    "    if not frames:\n",
    "        print('El video no es correcto o está mal escrito el nombre')\n",
    "        \n",
    "    \n",
    "    else:    \n",
    "        print (\"Video convertido en frames!\")\n",
    "        print ('Número de frames --->', len(frames))\n",
    "    return frames,numero_centros,nombres,frameRate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_histogramas(frames):\n",
    "    print('\\nSe han calculado los histogramas de los frames del video\\n')\n",
    "    colores = ['b','g','r']  \n",
    "    \n",
    "    #Array donde guardaremos los histogramas\n",
    "    hist=[]\n",
    "    \n",
    "    #recorremos los frames claculando los histogramas\n",
    "    for frame in frames:\n",
    "        #lo hacemos para los tres colores\n",
    "        feature_value=[cv2.calcHist([frame],[i],None,[16],[0,256]) for i,col in enumerate(colores)]\n",
    "        #se agregan a la lista todos juntos\n",
    "        hist.append(np.asarray(feature_value).flatten())\n",
    "    hist=np.asarray(hist)\n",
    "    \n",
    "    \n",
    "    # \"altura y anchura\" de hist\n",
    "    print (\"Forma del histograma (numero de frames y 256_intensidadColor*3_colores) ---> \" + str(hist.shape))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return hist\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(centros,hist):\n",
    "    #aplicamos kmeans a nuestro array de histogramas con nuestro número de centros calculados\n",
    "    kmeans=cluster.KMeans(n_clusters=centros, n_init=10).fit(hist)\n",
    "    print (\"\\nClustering o agrupamiento hecho!\")\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_resumen_frames(kmeans,hist,frames):\n",
    "    print('\\nGenerando resumen de frames')\n",
    "    \n",
    "    #Lista con los índices escogidos\n",
    "    frame_indices=[]\n",
    "    #Lista con los frames escogidos\n",
    "    frames_resumen=[]\n",
    "    \n",
    "    #hist_transform es una matriz en la que cada columna i indica\n",
    "    # la distancia de cada pixel al centro i\n",
    "    hist_transform=kmeans.transform(hist)\n",
    "    #print('histograma_transformado',hist_transform)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #para cada columna o cluster\n",
    "    for cluster in range(hist_transform.shape[1]):\n",
    "        \n",
    "        #calculamos el valor mínimo de la columna buscando el min de las filas de la traspuesta\n",
    "        #y lo añadimos al array de índices\n",
    "        frame_indices.append(np.argmin(hist_transform.T[cluster]))\n",
    "        \n",
    "    \n",
    "    \n",
    "    #ordenamos los frames en orden de aparición\n",
    "    #en el video para no tener saltos temporales\n",
    "    frame_indices=sorted(frame_indices)\n",
    "    \n",
    "    print ('\\nSe han escogido las siguientes POSICIONES (en los frames de sampleo) para el resumen:\\n', frame_indices)\n",
    "    \n",
    "    #metemos los frames que indican los índices en la lísta de los frames resumen\n",
    "    frames_resumen=[frames[i] for i in frame_indices]\n",
    "    #print(frames_resumen)\n",
    "    return frames_resumen,frame_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacar_vecinos_fluido(videoName,frames_indices,nombres):\n",
    "    \n",
    "    #volvemos a capturar el video original\n",
    "    cap = cv2.VideoCapture(videoName)\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    \n",
    "    #Array que contendrá los ids de los frames del video final\n",
    "    ids_finales=[]\n",
    "    \n",
    "    \n",
    "    #sacamos los frames del video original\n",
    "    while(cap.isOpened()):\n",
    "    \n",
    "        frameId = cap.get(1) #número del frame actual\n",
    "    \n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        \n",
    "        \n",
    "        #por cada frame del video original compruebo si su índice\n",
    "        #se encuentra dentro de los índices de los frames claves antes calculados\n",
    "        for pos in frame_indices:\n",
    "           \n",
    "            if (nombres[pos]==frameId):\n",
    "                #si el frame coincide cogemos 10 vecinos adyacentes por cada lado\n",
    "                if (frameId>10):\n",
    "                    for i in range(-10,11):\n",
    "                        filenameN = int(frameId+i)\n",
    "                        \n",
    "                        #Guardamos el id del frame escogido para el vídeo final\n",
    "                        ids_finales.append(filenameN)\n",
    "                else:\n",
    "                    #hay que tener en cuenta que el frame clave no sea de los 10 primeros para no coger ningún índice negativo\n",
    "                    for i in range(-frameId,frameId+11):\n",
    "                        filenameN =int(frameId+i)\n",
    "                        \n",
    "                        #Guardamos el id del frame escogido para el vídeo final\n",
    "                        ids_finales.append(filenameN)\n",
    "                        \n",
    "                        \n",
    "    #se cierra la captura\n",
    "    cap.release()\n",
    "    \n",
    "    return ids_finales\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez obtenidos todos los ids de los frames que compondrán el video final volvemos a \n",
    "#recorrer el video para capturar los frames\n",
    "\n",
    "def coger_frames_finales(videoName,ids_finales,imagesFolder):\n",
    "    \n",
    "    cap = cv2.VideoCapture(videoName)\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    \n",
    "    #Array que contendrá los frames del video final\n",
    "    framesFluid =[]\n",
    "   \n",
    "    while(cap.isOpened()):\n",
    "    \n",
    "        frameId = cap.get(1) \n",
    "    \n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        \n",
    "        \n",
    "        #por cada frame comprobamos si está su id entre los ids seleccionados\n",
    "        for t in ids_finales:\n",
    "            if(frameId ==t): \n",
    "                #escribimos la imagen\n",
    "                filename = imagesFolder + \"/image_\" +  str(t) + \".jpg\"\n",
    "                cv2.imwrite(filename, frame)\n",
    "                frame= cv2.imread(filename)\n",
    "                #la guardamos en el array\n",
    "                framesFluid.append(frame)\n",
    "            \n",
    "                        \n",
    "    #cerramos la captura\n",
    "    cap.release()\n",
    "    return framesFluid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_video_resumen(framesFluid, videoName, frameRate):\n",
    "    \n",
    "    # Nos quedamos con el nombre del video original sin el formato\n",
    "    videoSinFormato = videoName.split(\".\")\n",
    "    \n",
    "    # Obtener el tamaño del frame\n",
    "    altura, anchura = framesFluid[0].shape[:2]\n",
    "\n",
    "    # Especificar el códec\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "    # Inicializar VideoWriter con los parámetros correctos\n",
    "    salidaVideo = cv2.VideoWriter(videoSinFormato[0]+'-Resumen.avi', fourcc, frameRate, (anchura, altura))\n",
    "    \n",
    "    for frame in framesFluid:\n",
    "        salidaVideo.write(frame)\n",
    "    \n",
    "    salidaVideo.release()\n",
    "    \n",
    "    print('\\nVideo resumen creado!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecución de todos los métodos antes definidos\n",
    "\n",
    "\n",
    "print('Bienvenido al programa de Resumen Automático de Vídeos mediante Clasificación\\n\\nRealizado por Alfonso Alarcón Tamayo y Juan Manuel de la Oliva Aguilar\\n\\nPropuesto por el profesor Miguel Ángel Martínez del Amor para el\\ndpto. Ciencias de la Computación e Inteligencia Artificial de la Universidad de Sevilla 2017/18 ')\n",
    "\n",
    "print('\\n\\n\\nEMPEZAMOS!!!')\n",
    "print('\\nIntroduce el nombre del vídeo con el formato\\n(se tiene que especificar la ruta si el vídeo no se encuentra en la misma carpeta que el script)\\nEjemplo C:/Users/User1/Videos/video.mp4')\n",
    "\n",
    "#capturamos el nombre del video\n",
    "videoName = input()\n",
    "\n",
    "if len(videoName)==0:\n",
    "    print('\\nEl nombre del vídeo no puede estar vacío, por favor ejecute el script de nuevo.')\n",
    "else:\n",
    "    print('\\nIntroduce la ruta de la carpeta donde se guardarán los fotogramas:')\n",
    "    \n",
    "    #capturamos el nombre dela ruta para los frames\n",
    "    imagesFolder = input()\n",
    "    \n",
    "    if len(imagesFolder)==0:\n",
    "        print('\\nLa ruta no puede estar vacía, por favor ejecute el script de nuevo.')\n",
    "    else:\n",
    "        print('\\nConvirtiendo video en frames..\\n')\n",
    "\n",
    "        frames,numero_centros,nombres,frameRate = captura_videos_y_frames(videoName,imagesFolder)\n",
    "\n",
    "        hist=calcula_histogramas(frames)\n",
    "        print('\\nEl número de centros calculados es:')\n",
    "        print(numero_centros)\n",
    "\n",
    "        kmeans=clustering(int(numero_centros),hist)\n",
    "\n",
    "        frames_resumen,frame_indices= generar_resumen_frames(kmeans,hist,frames)\n",
    "\n",
    "        ids_finales=sacar_vecinos_fluido(videoName,frame_indices,nombres)\n",
    "\n",
    "        framesFluid=coger_frames_finales(videoName,ids_finales,imagesFolder)\n",
    "\n",
    "        crear_video_resumen(framesFluid,videoName,frameRate)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
